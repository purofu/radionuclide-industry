{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clinical Trial Radiopharmaceutical Analysis (Part 1: Setup and Constants)\n",
        "\n",
        "This notebook processes clinical trial data (expected in `consolidated_studies.json`) to identify studies involving specific radioisotopes and targets, focusing on interventional, industry-sponsored trials.\n",
        "\n",
        "**Part 1 includes:**\n",
        "1.  Importing necessary libraries.\n",
        "2.  Defining constants: file paths, radioisotope definitions, target definitions, keywords.\n",
        "3.  Setting up logging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports\n",
        "\n",
        "Import required Python libraries for data handling (json, collections), file operations (os), text processing (re), logging, type hinting, random sampling, and table formatting (tabulate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import logging\n",
        "from typing import Dict, List, Any, Tuple\n",
        "from collections import Counter, defaultdict\n",
        "!pip install tabulate # Ensure tabulate is installed\n",
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Constants\n",
        "\n",
        "Define input/output filenames, lists of radioisotope synonyms and their classifications, lists of target synonyms, keywords for identifying therapeutic intent, and valid study phases/purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------- File Paths --------------------\n",
        "INPUT_FILE = \"consolidated_studies.json\"\n",
        "OUTPUT_FILE = \"filtered_studies_output.json\" # Renamed for clarity\n",
        "OUTPUT_STATS_FILE = \"aggregated_stats_output.json\" # Renamed\n",
        "OUTPUT_VISUALIZATION_FILE = \"visualization_data_output.json\" # Renamed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# -------------------- Radionuclide Synonyms --------------------\n",
        "# Focus on brand/trial usage: no “mibg” in I-131, no plain “technetium” in Tc-99m, etc.\n",
        "RADIOISOTOPE_VARIANTS: Dict[str, List[str]] = {\n",
        "    # Positron Emitters\n",
        "    \"carbon-11\":      [\"carbon-11\", \"carbon 11\", \"c-11\", \"c 11\", \"11c\"],\n",
        "    \"nitrogen-13\":    [\"nitrogen-13\", \"nitrogen 13\", \"n-13\", \"n 13\", \"13n\"],\n",
        "    \"oxygen-15\":      [\"oxygen-15\", \"oxygen 15\", \"o-15\", \"o 15\", \"15o\"],\n",
        "    \"fluorine-18\":    [\"fluorine-18\", \"fluorine 18\", \"f-18\", \"f 18\", \"18f\", \"18f-fdg\", \"fdg\"],\n",
        "    \"copper-61\":      [\"copper-61\", \"copper 61\", \"cu-61\", \"cu 61\", \"61cu\"],\n",
        "    \"copper-64\":      [\"copper-64\", \"copper 64\", \"cu-64\", \"cu 64\", \"64cu\"],\n",
        "    \"gallium-66\":     [\"gallium-66\", \"gallium 66\", \"ga-66\", \"ga 66\", \"66ga\"],\n",
        "    \"gallium-68\":     [\"gallium-68\", \"gallium 68\", \"ga-68\", \"ga 68\", \"68ga\"],\n",
        "    \"rubidium-82\":    [\"rubidium-82\", \"rubidium 82\", \"rb-82\", \"rb 82\", \"82rb\"],\n",
        "    \"zirconium-89\":   [\"zirconium-89\", \"zirconium 89\", \"zr-89\", \"zr 89\", \"89zr\"],\n",
        "    \"iodine-124\":     [\"iodine-124\", \"iodine 124\", \"i-124\", \"i 124\", \"124i\"],\n",
        "\n",
        "    # Gamma\n",
        "    \"gallium-67\":       [\"gallium-67\", \"gallium 67\", \"ga-67\", \"ga 67\", \"67ga\"],\n",
        "    \"technetium-99m\":   [\"technetium-99m\", \"technetium 99m\", \"tc-99m\", \"tc 99m\", \"99mtc\"],\n",
        "    \"indium-111\":       [\"indium-111\", \"indium 111\", \"in-111\", \"in 111\", \"111in\"],\n",
        "    \"iodine-123\":       [\"iodine-123\", \"iodine 123\", \"i-123\", \"i 123\", \"123i\"],\n",
        "\n",
        "    # Beta emitters\n",
        "    \"phosphorus-32\":  [\"phosphorus-32\", \"phosphorus 32\", \"p-32\", \"p 32\", \"32p\"],\n",
        "    \"scandium-47\":    [\"scandium-47\", \"scandium 47\", \"sc-47\", \"sc 47\", \"47sc\"],\n",
        "    \"copper-67\":      [\"copper-67\", \"copper 67\", \"cu-67\", \"cu 67\", \"67cu\"],\n",
        "    \"strontium-89\":   [\"strontium-89\", \"strontium 89\", \"sr-89\", \"sr 89\", \"89sr\", \"metastron\"],\n",
        "    \"yttrium-90\":     [\"yttrium-90\", \"yttrium 90\", \"y-90\", \"y 90\", \"90y\"],\n",
        "    \"iodine-131\":     [\"iodine-131\", \"iodine 131\", \"i-131\", \"i 131\", \"131i\"],\n",
        "    \"holmium-166\":    [\"holmium-166\", \"holmium 166\", \"ho-166\", \"ho 166\", \"166ho\"],\n",
        "    \"lutetium-177\":   [\"lutetium-177\", \"lutetium 177\", \"lu-177\", \"lu 177\", \"177lu\"],\n",
        "    \"rhenium-186\":    [\"rhenium-186\", \"rhenium 186\", \"re-186\", \"re 186\", \"186re\"],\n",
        "    \"rhenium-188\":    [\"rhenium-188\", \"rhenium 188\", \"re-188\", \"re 188\", \"188re\"],\n",
        "    \"lead-212\":       [\"lead-212\", \"lead 212\", \"pb-212\", \"pb 212\", \"212pb\"],\n",
        "    \"samarium-153\":   [\"samarium-153\", \"samarium 153\", \"sm-153\", \"sm 153\", \"153sm\", \"quadramet\"],\n",
        "\n",
        "    # Alpha\n",
        "    \"astatine-211\":   [\"astatine-211\", \"astatine 211\", \"at-211\", \"at 211\", \"211at\"],\n",
        "    \"bismuth-213\":    [\"bismuth-213\", \"bismuth 213\", \"bi-213\", \"bi 213\", \"213bi\"],\n",
        "    \"actinium-225\":   [\"actinium-225\", \"actinium 225\", \"ac-225\", \"ac 225\", \"225ac\"],\n",
        "    \"radium-223\":     [\"radium-223\", \"radium 223\", \"ra-223\", \"ra 223\", \"223ra\", \"xofigo\"],\n",
        "    \"thorium-227\":    [\"thorium-227\", \"thorium 227\", \"th-227\", \"th 227\", \"227th\"],\n",
        "\n",
        "    # Auger\n",
        "    \"bromine-77\":     [\"bromine-77\", \"bromine 77\", \"br-77\", \"br 77\", \"77br\"],\n",
        "    \"iodine-125\":     [\"iodine-125\", \"iodine 125\", \"i-125\", \"i 125\", \"125i\"],\n",
        "    \"platinum-191\":   [\"platinum-191\", \"platinum 191\", \"pt-191\", \"pt 191\", \"191pt\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------- Radionuclide Classification --------------------\n",
        "# Classification: \"type\" (physical), \"therapeutic\": bool, \"application\": \"diagnostic\"|\"therapeutic\"|\"both\"\n",
        "RADIOISOTOPE_CLASSIFICATION: Dict[str, Dict[str, Any]] = {\n",
        "    # Positron\n",
        "    \"carbon-11\":      {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"nitrogen-13\":    {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"oxygen-15\":      {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"fluorine-18\":    {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"copper-61\":      {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"copper-64\":      {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"both\"}, # Theranostic potential\n",
        "    \"gallium-66\":     {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"gallium-68\":     {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"rubidium-82\":    {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"zirconium-89\":   {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"iodine-124\":     {\"type\": \"positron\", \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "\n",
        "    # Gamma\n",
        "    \"gallium-67\":       {\"type\": \"gamma\",    \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"technetium-99m\":   {\"type\": \"gamma\",    \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"indium-111\":       {\"type\": \"gamma\",    \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "    \"iodine-123\":       {\"type\": \"gamma\",    \"therapeutic\": False, \"application\": \"diagnostic\"},\n",
        "\n",
        "    # Beta\n",
        "    \"phosphorus-32\":  {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"scandium-47\":    {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"}, # Also gamma emission (theranostic)\n",
        "    \"copper-67\":      {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"strontium-89\":   {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"yttrium-90\":     {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"iodine-131\":     {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"}, # Also gamma emission\n",
        "    \"holmium-166\":    {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"lutetium-177\":   {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"}, # Also gamma emission\n",
        "    \"rhenium-186\":    {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"rhenium-188\":    {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"lead-212\":       {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"}, # Primarily therapeutic due to alpha daughters (Ac-225 pathway analog)\n",
        "    \"samarium-153\":   {\"type\": \"beta\",     \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "\n",
        "    # Alpha\n",
        "    \"astatine-211\":   {\"type\": \"alpha\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"bismuth-213\":    {\"type\": \"alpha\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"actinium-225\":   {\"type\": \"alpha\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"radium-223\":     {\"type\": \"alpha\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"thorium-227\":    {\"type\": \"alpha\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "\n",
        "    # Auger\n",
        "    \"bromine-77\":     {\"type\": \"auger\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"iodine-125\":     {\"type\": \"auger\",    \"therapeutic\": True,  \"application\": \"therapeutic\"},\n",
        "    \"platinum-191\":   {\"type\": \"auger\",    \"therapeutic\": True,  \"application\": \"therapeutic\"}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------- Isotope Synonym Map Generation --------------------\n",
        "ISOTOPE_SYNONYM_MAP: Dict[str, str] = {}\n",
        "for standard, synonyms in RADIOISOTOPE_VARIANTS.items():\n",
        "    if standard not in RADIOISOTOPE_CLASSIFICATION:\n",
        "        # Use logging later once it's configured\n",
        "        print(f\"WARNING: Isotope '{standard}' in VARIANTS missing from CLASSIFICATION.\") \n",
        "        continue\n",
        "    for s in synonyms:\n",
        "        ISOTOPE_SYNONYM_MAP[s.lower()] = standard\n",
        "\n",
        "# print(f\"Generated {len(ISOTOPE_SYNONYM_MAP)} isotope synonym mappings.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------- Target Synonyms --------------------\n",
        "# Based on user-provided list, refined and grouped\n",
        "KNOWN_TARGETS: Dict[str, List[str]] = {\n",
        "    # Using the second, more comprehensive list provided\n",
        "    \"psma\": [\"psma\", \"prostate specific membrane antigen\", \"psma-617\", \"psma-11\", \"psma 617\", \"psma 11\", \"psma-r2\", \"rhpsma\", \"gozetotide\", \"vipivotide tetraxetan\", \"psma5\", \"pelgifatamab\", \"psma-trillium\", \"sar-bispsma\"],\n",
        "    \"sstr\": [\"sstr\", \"somatostatin receptor\", \"sstr2\", \"dotatate\", \"dotatoc\", \"dotanoc\", \"edotreotide\", \"lanreotide\", \"octreotide\", \"sartate\", \"ebtate\"], # Grouped SSTRs\n",
        "    \"fap\": [\"fap\", \"fibroblast activation protein\", \"fapi\", \"fapi-46\", \"fapi-74\", \"sar-bisfap\"],\n",
        "    \"grpr\": [\"grpr\", \"gastrin-releasing peptide receptor\", \"bombesin\", \"bombesin receptor\", \"neob\", \"sar-bombesin\"],\n",
        "    \"her2\": [\"her2\", \"her-2\", \"human epidermal growth factor receptor 2\", \"trastuzumab\", \"sar-trastuzumab\"],\n",
        "    \"caix\": [\"caix\", \"carbonic anhydrase ix\", \"girentuximab\"],\n",
        "    \"caxii\": [\"caxii\", \"carbonic anhydrase xii\", \"lucafab\"],\n",
        "    \"lat\": [\"lat\", \"lat1\", \"lat2\", \"amino acid transport\", \"ipa\", \"floretyrosine\"], # LAT includes related terms\n",
        "    \"cd66\": [\"cd66\", \"cea\", \"ceacam5\", \"besilesomab\"], # CD66 often used for imaging inflammation/infection\n",
        "    \"pd1\": [\"pd1\", \"pd-1\", \"programmed death-1\"],\n",
        "    \"pdl1\": [\"pdl1\", \"pd-l1\", \"programmed death-ligand 1\", \"nm-01\"],\n",
        "    \"egfr\": [\"egfr\", \"epidermal growth factor receptor\"],\n",
        "    \"cmet\": [\"cmet\", \"met\"], # Often targeted with EGFR\n",
        "    \"cxcr4\": [\"cxcr4\", \"chemokine receptor 4\"],\n",
        "    \"integrin\": [\"integrin\", \"αvβ3\", \"αvβ5\", \"αvβ6\", \"ebrgd\", \"avb3\", \"avb5\", \"avb6\", \"alphavbeta3\", \"alphavbeta5\", \"alphavbeta6\"], # Simplified main variant + alpha numerics\n",
        "    \"ntsr1\": [\"ntsr1\", \"neurotensin receptor 1\"],\n",
        "    \"prrnt\": [\"prrnt\", \"peptide receptor radionuclide therapy\", \"prrt\"], # More a therapy type than a target - keep for now if mentioned explicitly\n",
        "    \"ccr2\": [\"ccr2\", \"cc chemokine receptor 2\"],\n",
        "    \"trop2\": [\"trop-2\", \"trop2\"],\n",
        "    \"necrosis\": [\"necrosis\", \"hypoxia\", \"hif\", \"tumor necrosis\"], # Treatment condition/target\n",
        "    \"gd2\": [\"gd2\", \"disialoganglioside gd2\", \"gd2-sada\"],\n",
        "    \"cd38\": [\"cd38\", \"cd-38\", \"cd38-sada\"],\n",
        "    \"igf-1r\": [\"igf-1r\", \"insulin-like growth factor 1 receptor\", \"fpi-1547\"],\n",
        "    \"pdgfra\": [\"pdgfra\", \"platelet-derived growth factor receptor alpha\", \"olaratumab\"],\n",
        "    \"nis\": [\"nis\", \"sodium-iodide symporter\", \"af-001\"],\n",
        "    \"dll3\": [\"dll3\", \"delta-like ligand 3\", \"abd-147\"],\n",
        "    \"lrrc15\": [\"lrrc15\", \"leucine rich repeat containing 15\", \"dunp19\"],\n",
        "    \"ptpµ\": [\"ptpµ\", \"ptpmu\", \"protein tyrosine phosphatase mu\"], # ASCII variant\n",
        "    \"fr\": [\"fr\", \"folate receptor\"], # Folate Receptor\n",
        "    \"hk2\": [\"hk2\", \"hexokinase 2\"],\n",
        "    \"lag3\": [\"lag3\"],\n",
        "    \"cd25\": [\"cd25\", \"il-2 receptor alpha\"],\n",
        "    \"b7h3\": [\"b7h3\", \"cd276\"],\n",
        "    \"cd45\": [\"cd45\"],\n",
        "    \"cd70\": [\"cd70\"],\n",
        "    \"cd8\": [\"cd8\"],\n",
        "    \"cd44v6\": [\"cd44v6\"],\n",
        "    \"claudin18.2\": [\"claudin18.2\", \"claudin 18.2\"],\n",
        "    \"gpc3\": [\"gpc3\", \"glypican-3\"],\n",
        "    \"cck2r\": [\"cck2r\", \"cholecystokinin-2 receptor\", \"cckbr\", \"gastrin receptor\"],\n",
        "    \"glp1r\": [\"glp1r\", \"glucagon-like peptide-1 receptor\"],\n",
        "    \"bone\": [\"bone\", \"bone metastases\"], # Generic bone targeting\n",
        "    \"ple\": [\"ple\", \"phospholipid ether\", \"clr\", \"iopofosine\", \"cellectar\"], # Target for Cellectar's platform\n",
        "    \"fatty acid oxidation\": [\"fatty acid oxidation\", \"pivalate\"],\n",
        "    \"thyroid\": [\"thyroid\"], # Added as target for I-131 therapy\n",
        "    \"neuroblastoma\": [\"neuroblastoma\"], # Added as target for MIBG therapy\n",
        "    \"upar\": [\"upar\", \"urokinase plasminogen activator receptor\", \"plaúr\"],\n",
        "    \"cd20\": [\"cd20\", \"cd-20\", \"rituximab\", \"ibritumomab\", \"ofatumumab\", \"obinutuzumab\"], # Added CD20 from first list + common drugs\n",
        "    \"xct\": [\"xct\", \"cystine/glutamate antiporter\", \"xc-\", \"slc7a11\"],\n",
        "    \"estrogen_receptor\": [\"estrogen receptor\", \"er\", \"17ß-estradiol\", \"estradiol\"], # Combined ER and estradiol\n",
        "    # Other potential concepts/molecules mentioned\n",
        "    \"mibg\": [\"mibg\", \"metaiodobenzylguanidine\"],\n",
        "    \"fet\": [\"fet\", \"fluoroethyl-l-tyrosine\"], # Might be tracer not target\n",
        "    \"glucose_transport\": [\"glucose transport\", \"fdg\"], # Functional category, include FDG\n",
        "    \"parp\": [\"parp\", \"poly (adp-ribose) polymerase\"],\n",
        "    \"chondroitin_sulfate\": [\"chondroitin sulfate\"],\n",
        "    \"ace2\": [\"ace2\", \"ace-2\"],\n",
        "    \"biotin\": [\"biotin\"],\n",
        "    \"gpcr\": [\"gpcr\", \"g protein-coupled receptor\"], # Functional class\n",
        "    \"granzyme_b\": [\"granzyme b\", \"granzyme-b\", \"grb\", \"grip-b\"],\n",
        "    \"mc1r\": [\"mc1r\", \"melanocortin 1 receptor\"],\n",
        "    \"mc2r\": [\"mc2r\", \"acth receptor\"],\n",
        "    \"nectin4\": [\"nectin-4\", \"nectin4\"],\n",
        "    \"net_transporter\": [\"net\", \"norepinephrine transporter\", \"slc6a2\"],\n",
        "    \"ptk7\": [\"ptk7\", \"protein tyrosine kinase 7\"],\n",
        "    \"fspg\": [\"fspg\"], # Unclear, keeping as is\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------- Target Synonym Map Generation --------------------\n",
        "TARGET_SYNONYM_MAP: Dict[str, str] = {}\n",
        "for standard, synonyms in KNOWN_TARGETS.items():\n",
        "    # Optionally add a check here if standard is missing from TARGET_CATEGORIES if using categories later\n",
        "    for s in synonyms:\n",
        "        TARGET_SYNONYM_MAP[s.lower()] = standard\n",
        "\n",
        "# print(f\"Generated {len(TARGET_SYNONYM_MAP)} target synonym mappings.\")\n",
        "\n",
        "# Optional: Define TARGET_CATEGORIES if you plan to use them later for analysis/reporting\n",
        "# TARGET_CATEGORIES: Dict[str, List[str]] = { ... } # Your categories dictionary here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------- Therapeutic / Imaging Keywords (Refined) --------------------\n",
        "# Combine the provided lists for a more comprehensive check\n",
        "\n",
        "# Using the original list as a base and adding specifics\n",
        "THERAPEUTIC_KEYWORDS = sorted(list(set(\n",
        "    # Original keywords\n",
        "    [\"therapy\", \"treatment\", \"treat\", \"therapeutic\", \"theranostic\",\n",
        "     \"palliative\", \"curative\", \"radioligand\", \"radionuclide\", \"rlt\", \"prrt\",\n",
        "     \"radioimmunotherapy\", \"radioembolization\", \"brachytherapy\"]\n",
        "    +\n",
        "    # Specific radiopharmaceutical terms\n",
        "    [\"radioligand therapy\", \"radionuclide therapy\", \"radiopharmaceutical therapy\", \"radioimmunotherapy\",\n",
        "     \"targeted radionuclide\", \"radioembolization\", \"radiosynovectomy\", \"radioisotope therapy\",\n",
        "     \"peptide receptor radionuclide therapy\", \"targeted alpha therapy\", \"targeted alpha particle\",\n",
        "     \"targeted beta particle\", \"radiotherapy\", \"alpha therapy\", \"beta therapy\", \"auger therapy\"]\n",
        "    +\n",
        "    # Specific known therapeutic agents (lowercase)\n",
        "    [\"xofigo\", \"lutathera\", \"pluvicto\", \"azedra\", \"zevalin\", \"bexxar\", \"quadramet\",\n",
        "     \"metastron\", \"therasphere\", \"sir-spheres\", \"alphamedix\", \"iopofosine\"]\n",
        ")), key=len, reverse=True) # Sort longest first might help simple search\n",
        "\n",
        "# Optional: Define imaging keywords if needed for more nuanced classification\n",
        "IMAGING_ONLY_KEYWORDS = sorted(list(set(\n",
        "    [\"diagnostic imaging\", \"positron emission tomography\", \"pet scan\", \"pet/ct\", \"spect\", \"spect/ct\",\n",
        "     \"pet imaging\", \"diagnostic use only\", \"nuclear medicine imaging\", \"diagnostic tool\",\n",
        "     \"diagnostic imaging agent\", \"biodistribution study\", \"dosimetry study\", \"imaging agent\",\n",
        "     \"diagnostic\", \"diagnosis\", \"detection\", \"monitoring\", \"localization\", \"staging\", \"imaging study\", \"scan\"]\n",
        ")), key=len, reverse=True)\n",
        "\n",
        "# -------------------- Other Constants --------------------\n",
        "VALID_PHASES = {\"PHASE1\", \"PHASE2\", \"PHASE3\", \"PHASE4\", \"EARLY_PHASE1\"}\n",
        "THERAPY_PURPOSES = {\"TREATMENT\", \"SUPPORTIVE_CARE\", \"PALLIATIVE\", \"PREVENTION\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Logging Setup\n",
        "\n",
        "Configure basic logging to display informational messages during script execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,  # Set to logging.DEBUG for more verbose output\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers=[\n",
        "        logging.StreamHandler() # Output logs to the notebook console\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Example log message\n",
        "# logger.info(\"Logging configured.\")"
      ]
    },

  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "# Clinical Trial Radiopharmaceutical Analysis (Part 2: Helper Functions)\n",
      "\n",
      "This section defines various helper functions used throughout the analysis pipeline.\n",
      "\n",
      "**Functions included:**\n",
      "* Text normalization\n",
      "* Isotope extraction (from interventions only)\n",
      "* Target extraction (from multiple fields)\n",
      "* Therapeutic intent checking\n",
      "* Sponsor categorization and extraction\n",
      "* Trial phase mapping\n",
      "* Debugging/verification helpers"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "## 4. Helper Functions"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.1 Text Normalization\n",
      "\n",
      "Function to clean and standardize text for consistent matching."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def normalize_text(text: str) -> str:\n",
      "    \"\"\"\n",
      "    Cleans text by removing punctuation (except hyphens), converting to lowercase,\n",
      "    and standardizing whitespace.\n",
      "    \"\"\"\n",
      "    if not text or not isinstance(text, str):\n",
      "        return \"\"\n",
      "    # Remove punctuation except hyphens, convert to lowercase\n",
      "    text = re.sub(r'[^\\w\\s-]', '', text.lower())\n",
      "    # Standardize whitespace (replace multiple spaces/tabs/newlines with single space)\n",
      "    return \" \".join(text.strip().split())"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.2 Isotope Extraction\n",
      "\n",
      "Extracts standardized radioisotope names specifically mentioned within the `interventions` section of a study's protocol."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def extract_isotopes_from_interventions_only(arms_block: Dict) -> List[str]:\n",
      "    \"\"\"\n",
      "    Extract radioisotopes specifically from the 'interventions' section (by 'name'),\n",
      "    ignoring any mention in the brief/official title. Uses ISOTOPE_SYNONYM_MAP.\n",
      "    Returns a sorted list of unique, standardized isotope names.\n",
      "    \"\"\"\n",
      "    found = set()\n",
      "    if not arms_block or not isinstance(arms_block, dict):\n",
      "        return []\n",
      "    interventions = arms_block.get(\"interventions\", [])\n",
      "    if not isinstance(interventions, list):\n",
      "        return []\n",
      "\n",
      "    # Sort isotope synonyms by length, descending, to match longer names first\n",
      "    # (e.g., \"technetium-99m\" before \"tc-99m\")\n",
      "    sorted_variants = sorted(ISOTOPE_SYNONYM_MAP.keys(), key=len, reverse=True)\n",
      "\n",
      "    for iv in interventions:\n",
      "        if not isinstance(iv, dict):\n",
      "            continue\n",
      "        iv_name = iv.get(\"name\", \"\")\n",
      "        norm_iv = normalize_text(iv_name)\n",
      "        if not norm_iv:\n",
      "             continue\n",
      "\n",
      "        # Search for each variant in the normalized intervention name\n",
      "        temp_norm_iv = norm_iv # Work on a copy if removing found terms\n",
      "        for variant in sorted_variants:\n",
      "            # Use word boundaries to ensure whole word/term match\n",
      "            pattern = r\"\\b\" + re.escape(variant) + r\"\\b\"\n",
      "            if re.search(pattern, temp_norm_iv):\n",
      "                standard_isotope = ISOTOPE_SYNONYM_MAP[variant]\n",
      "                found.add(standard_isotope)\n",
      "                # Optional: remove found term to prevent partial re-matches (crude)\n",
      "                # temp_norm_iv = temp_norm_iv.replace(variant, \"\") \n",
      "\n",
      "    return sorted(list(found))"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.3 Target Extraction\n",
      "\n",
      "Extracts standardized target names by searching for synonyms across multiple text fields within the protocol section (titles, summaries, interventions, keywords)."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def extract_targets(protocol_section: Dict) -> List[str]:\n",
      "    \"\"\"\n",
      "    Extract potential targets based on keywords/synonyms found in titles,\n",
      "    summaries, interventions, and keywords sections of the protocol.\n",
      "    Uses the TARGET_SYNONYM_MAP.\n",
      "    Returns a sorted list of unique, standardized target names.\n",
      "    \"\"\"\n",
      "    found_targets = set()\n",
      "    if not protocol_section or not isinstance(protocol_section, dict):\n",
      "        return []\n",
      "\n",
      "    # Get relevant text fields from different modules\n",
      "    id_module = protocol_section.get(\"identificationModule\", {})\n",
      "    desc_module = protocol_section.get(\"descriptionModule\", {})\n",
      "    arms_module = protocol_section.get(\"armsInterventionsModule\", {})\n",
      "    # Keywords might be under identification or a separate module\n",
      "    keywords_list = id_module.get(\"keywords\", []) \n",
      "    if not keywords_list: # Fallback check if structure varies\n",
      "         keywords_module = protocol_section.get(\"keywordsModule\", {})\n",
      "         keywords_list = keywords_module.get(\"keywords\", [])\n",
      "\n",
      "    # Normalize text from various sources\n",
      "    brief_title = normalize_text(id_module.get(\"briefTitle\", \"\"))\n",
      "    official_title = normalize_text(id_module.get(\"officialTitle\", \"\"))\n",
      "    brief_summary = normalize_text(desc_module.get(\"briefSummary\", \"\"))\n",
      "    detailed_desc = normalize_text(desc_module.get(\"detailedDescription\", \"\"))\n",
      "    \n",
      "    # Extract and normalize intervention names\n",
      "    interventions = arms_module.get(\"interventions\", [])\n",
      "    intervention_texts = \"\"\n",
      "    if isinstance(interventions, list):\n",
      "        intervention_texts = \" \".join([normalize_text(iv.get(\"name\", \"\")) for iv in interventions if isinstance(iv, dict)])\n",
      "\n",
      "    # Extract and normalize keywords (assuming it's a list of strings)\n",
      "    keywords_text = \"\"\n",
      "    if isinstance(keywords_list, list):\n",
      "         keywords_text = \" \".join([normalize_text(kw) for kw in keywords_list if isinstance(kw, str)])\n",
      "\n",
      "    # Combine all text sources into one large string for searching\n",
      "    combined_text = \" \".join([brief_title, official_title, brief_summary, detailed_desc, intervention_texts, keywords_text])\n",
      "\n",
      "    if not combined_text.strip():\n",
      "        return [] # No text to search\n",
      "\n",
      "    # Use the pre-computed map with lowercase keys\n",
      "    # Sort target synonyms by length, descending, to match longer phrases first\n",
      "    sorted_target_synonyms = sorted(TARGET_SYNONYM_MAP.keys(), key=len, reverse=True)\n",
      "\n",
      "    temp_combined_text = combined_text # Work on a copy if removing terms\n",
      "    for synonym in sorted_target_synonyms:\n",
      "        # Use word boundaries to avoid partial matches within words\n",
      "        pattern = r\"\\b\" + re.escape(synonym) + r\"\\b\"\n",
      "        # Search in the current state of the text\n",
      "        if re.search(pattern, temp_combined_text):\n",
      "            standard_target = TARGET_SYNONYM_MAP[synonym]\n",
      "            found_targets.add(standard_target)\n",
      "            # Optional: remove found synonym to avoid re-matching parts of it (e.g., matching 'psma' after 'sar-bispsma')\n",
      "            # This is crude and might remove legitimate separate mentions.\n",
      "            # Consider more sophisticated NLP if needed.\n",
      "            # temp_combined_text = temp_combined_text.replace(synonym, \"\") \n",
      "\n",
      "    return sorted(list(found_targets))"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.4 Therapeutic Intent and Isotope Checks\n",
      "\n",
      "Functions to determine if a study has therapeutic intent based on its design, purpose, and keywords, and to check if a study involves any isotopes classified as therapeutic."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def check_therapeutic_intent(study: Dict) -> bool:\n",
      "    \"\"\"\n",
      "    Decide if a study is 'therapeutic' in design, based on multiple criteria:\n",
      "    - Study type must be INTERVENTIONAL.\n",
      "    - Checks phase, primary purpose, and keywords in titles/interventions.\n",
      "    - Uses the refined THERAPEUTIC_KEYWORDS list.\n",
      "    \"\"\"\n",
      "    raw = study.get(\"original_data\", {})\n",
      "    proto = raw.get(\"protocolSection\", {})\n",
      "    if not proto:\n",
      "        return False\n",
      "\n",
      "    design = proto.get(\"designModule\", {})\n",
      "    study_type = design.get(\"studyType\", \"\").upper()\n",
      "    # Rule 1: Must be Interventional\n",
      "    if study_type != \"INTERVENTIONAL\":\n",
      "        return False\n",
      "\n",
      "    # Rule 2: Check for therapeutic signals (Phase, Purpose, Keywords)\n",
      "    phases = design.get(\"phases\", [])\n",
      "    has_valid_phase = any(ph.upper() in VALID_PHASES for ph in phases)\n",
      "    primary_purpose = (design.get(\"primaryPurpose\") or \"\").upper()\n",
      "    is_therapy_purpose = (primary_purpose in THERAPY_PURPOSES)\n",
      "\n",
      "    # Check keywords in title/interventions using the refined THERAPEUTIC_KEYWORDS list\n",
      "    id_block = proto.get(\"identificationModule\", {})\n",
      "    arms_block = proto.get(\"armsInterventionsModule\", {})\n",
      "    btitle_norm = normalize_text(id_block.get(\"briefTitle\", \"\"))\n",
      "    otitle_norm = normalize_text(id_block.get(\"officialTitle\", \"\"))\n",
      "\n",
      "    # Combine relevant text fields for keyword search\n",
      "    search_text = btitle_norm + \" \" + otitle_norm\n",
      "    interventions = arms_block.get(\"interventions\", [])\n",
      "    if isinstance(interventions, list):\n",
      "        intervention_names = \" \".join([normalize_text(iv.get(\"name\", \"\")) for iv in interventions if isinstance(iv, dict)])\n",
      "        search_text += \" \" + intervention_names\n",
      "        \n",
      "    found_keyword = False\n",
      "    if search_text.strip():\n",
      "         # Iterate through keywords (sorted longest first) and check using regex\n",
      "         for kw in THERAPEUTIC_KEYWORDS:\n",
      "              pattern = r'\\b' + re.escape(kw) + r'\\b'\n",
      "              if re.search(pattern, search_text):\n",
      "                   found_keyword = True\n",
      "                   break # Found one therapeutic keyword, no need to check others\n",
      "\n",
      "    # A study is considered therapeutic if it meets phase/purpose criteria OR has a keyword\n",
      "    is_therapeutic = bool(has_valid_phase or is_therapy_purpose or found_keyword)\n",
      "\n",
      "    # Optional Refinement: Check for explicit imaging-only keywords\n",
      "    # If an imaging keyword is found, potentially override the therapeutic flag?\n",
      "    # This requires careful consideration of edge cases (e.g., theranostic trials)\n",
      "    # found_imaging_keyword = False\n",
      "    # if search_text.strip():\n",
      "    #      for kw in IMAGING_ONLY_KEYWORDS:\n",
      "    #           pattern = r'\\b' + re.escape(kw) + r'\\b'\n",
      "    #           if re.search(pattern, search_text):\n",
      "    #                found_imaging_keyword = True\n",
      "    #                break\n",
      "    # \n",
      "    # if is_therapeutic and found_imaging_keyword:\n",
      "    #      # Handle potential conflict - maybe log it or apply specific rules\n",
      "    #      # For now, let's keep it simple: therapeutic signal takes precedence\n",
      "    #      pass \n",
      "         \n",
      "    return is_therapeutic\n",
      "\n",
      "def has_any_therapeutic_isotope(radioisotopes: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Checks if any isotope in the provided list is classified as therapeutic\n",
      "    (i.e., 'therapeutic': True or 'application': 'both' in RADIOISOTOPE_CLASSIFICATION).\n",
      "    \"\"\"\n",
      "    if not radioisotopes:\n",
      "        return False\n",
      "    for iso in radioisotopes:\n",
      "        classification = RADIOISOTOPE_CLASSIFICATION.get(iso, {})\n",
      "        if classification.get(\"therapeutic\") or classification.get(\"application\") == \"both\":\n",
      "            return True\n",
      "    return False"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.5 Sponsor Categorization and Extraction\n",
      "\n",
      "Functions to categorize sponsors (Industry, Academic, Government, etc.) based on keywords in their names and consolidate known variations. Then extracts lead and collaborator sponsors from the protocol data."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def categorize_and_consolidate_organization(org_name: str) -> Tuple[str, str]:\n",
      "    \"\"\"\n",
      "    Categorize sponsor name (INDUSTRY, ACADEMIC, GOV, FOUNDATION/NON-PROFIT, OTHER).\n",
      "    Also attempts to unify certain synonyms to major corporate names.\n",
      "    Returns: (category, consolidated_name)\n",
      "    \"\"\"\n",
      "    if not org_name or not isinstance(org_name, str):\n",
      "        return \"UNKNOWN\", \"UNKNOWN\"\n",
      "    \n",
      "    org_lower = org_name.lower()\n",
      "    category = \"OTHER\" # Default category\n",
      "    consolidated_name = org_name # Default name\n",
      "\n",
      "    # --- Specific Consolidations (Hardcoded - expand as needed) ---\n",
      "    # Order matters if names overlap (e.g., subsidiary before parent if checking both)\n",
      "    if \"advanced accelerator applications\" in org_lower or org_lower == \"aaa\":\n",
      "        consolidated_name = \"Novartis\" # AAA is part of Novartis\n",
      "        category = \"INDUSTRY\"\n",
      "    elif \"point biopharma\" in org_lower and \"eli lilly\" in org_lower:\n",
      "         consolidated_name = \"Eli Lilly and Company\" # Point acquired by Lilly\n",
      "         category = \"INDUSTRY\"\n",
      "    elif \"point biopharma\" in org_lower: # Check after Lilly combo\n",
      "         consolidated_name = \"Point Biopharma\" # Or map to Lilly? Decide consistency.\n",
      "         category = \"INDUSTRY\"\n",
      "    elif \"janssen pharmaceutica\" in org_lower or \"janssen r&d\" in org_lower:\n",
      "        consolidated_name = \"Janssen\" # Part of J&J\n",
      "        category = \"INDUSTRY\"\n",
      "    elif \"bayer healthcare pharmaceuticals\" in org_lower or \"bayer schering pharma\" in org_lower:\n",
      "        consolidated_name = \"Bayer\"\n",
      "        category = \"INDUSTRY\"\n",
      "    elif org_lower in [\"biocompatibles uk ltd, a bt international group company\", \"biocompatibles uk ltd\"]:\n",
      "        consolidated_name = \"Biocompatibles UK Ltd\" # Specific entity\n",
      "        category = \"INDUSTRY\"\n",
      "    elif \"australian nuclear science and technology organisation\" in org_lower or org_lower == \"ansto\":\n",
      "        consolidated_name = \"ANSTO\"\n",
      "        category = \"GOVERNMENT\" # ANSTO is a government agency\n",
      "    elif org_lower == \"novartis pharmaceuticals\":\n",
      "        consolidated_name = \"Novartis\"\n",
      "        category = \"INDUSTRY\"\n",
      "    elif \"memorial sloan kettering\" in org_lower:\n",
      "         consolidated_name = \"Memorial Sloan Kettering Cancer Center\"\n",
      "         category = \"ACADEMIC\"\n",
      "    elif \"md anderson cancer center\" in org_lower:\n",
      "         consolidated_name = \"MD Anderson Cancer Center\"\n",
      "         category = \"ACADEMIC\"\n",
      "    # Add more specific consolidations here...\n",
      "    \n",
      "    # --- General Categorization Keywords ---\n",
      "    # Check category only if not already set by specific consolidation\n",
      "    if category == \"OTHER\": \n",
      "        c_lower = consolidated_name.lower() # Use potentially consolidated name for category check\n",
      "        \n",
      "        # Order: Check Industry first, then Academic, Gov, Foundation, finally Other\n",
      "        industry_indicators = [\n",
      "            \"inc.\", \"corp\", \"pharma\", \"therapeutics\", \"biopharma\", \"llc\", \"s.a.\", \"s.l.\", \"gmbh\", \"ltd\", \"limited\", \"ag\",\n",
      "            \"sas\", \"pty ltd\", \"biotech\", \"diagnostics\", \"solutions\", \"pharmaceutical\", \"innovations\", \"ventures\", \"group\",\n",
      "            \"holdings\", \"novartis\", \"bayer\", \"roche\", \"pfizer\", \"gsk\", \"sanofi\", \"astrazeneca\", \"merck\", \"lilly\",\n",
      "            \"abbvie\", \"bristol myers\", \"janssen\", \"celgene\", \"amgen\", \"gilead\", \"biogen\", \"regeneron\", \"moderna\",\n",
      "            \"takeda\", \"telix\", \"clarity\", \"itm\", \"ratio\", \"radiopharm\", \"abdera\", \"artbio\", \"cellectar\", \"alpha fusion\",\n",
      "            \"molecular targeting\", \"jubilant\", \"y-mabs\", \"blue earth\", \"point bio\", \"excel diagnostics\",\n",
      "            \"isotope technologies munich\", \"convergent\", \"perspective\", \"curium\", \"orano med\", \"plus therapeutics\",\n",
      "            \"boston scientific\", \"corixa\", \"sinotau\", \"biocompatibles\", \"cytogen\", \"terumo\", \"varian\", \"astellas\",\n",
      "            \"theragenics\", \"nanomab\", \"lantheus\", \"eckert & ziegler\", \"radiomedix\", \"radiopharm theranostics\",\n",
      "            \"company\", \"co.\", \"incorporated\", \"corporation\", \" plc\", \"b.v.\", \"s.p.a.\"\n",
      "        ]\n",
      "        academic_indicators = [\n",
      "            \"university\", \"college\", \"school of\", \"medical center\", \"fondazione\", \"hospital\", \"clinic\", \"institute\",\n",
      "            \"center for\", \"hopitaux\", \"klinik\", \"karolinska\", \"cancer center\", \"research foundation\", \"academisch\",\n",
      "            \"universita\", \"universite\", \"universität\", \"charite\", \"md anderson\", \"memorial sloan\", \"dana-farber\",\n",
      "            \"health system\", \"healthcare\", \"erasmus mc\", \"radboud university\", \"ucla\", \"ucsf\", \"stanford\", \"yale\", \"harvard\",\n",
      "            \"johns hopkins\", \"mayo clinic\", \"cleveland clinic\", \"institut curie\", \"gustave roussy\", \"peter maccallum\"\n",
      "        ]\n",
      "        gov_indicators = [\n",
      "            \"national institutes\", \"nih\", \"nci\", \"fda\", \"cdc\", \"inserm\", \"health and human services\", \"veterans affairs\",\n",
      "            \"ministry of health\", \"department of\", \"va medical\", \"government\", \"public health\", \"atomic energy\",\n",
      "            \"european organisation for research and treatment\", \"eortc\", \"medical research council\", \"mrc\", \"ansto\"\n",
      "        ]\n",
      "        foundation_nonprofit = [\n",
      "            \"foundation\", \"stiftung\", \"non-profit\", \"nonprofit\", \"charity\", \"trust\", \"cooperative oncology group\", \"trials group\",\n",
      "            \"alliance\", \"ecog\", \"swog\", \"nrg oncology\", \"rtog\", \"australasian gastro-intestinal trials group\",\n",
      "            \"anzuptg\", \"gocor\", \"german colorectal cancer study group\", \"cancer research uk\", \"fondation\"\n",
      "        ]\n",
      "\n",
      "        # Use regex with word boundaries for more precise matching\n",
      "        if any(re.search(r'\\b' + re.escape(w) + r'(?![a-z0-9])', c_lower) for w in industry_indicators):\n",
      "            category = \"INDUSTRY\"\n",
      "        elif any(re.search(r'\\b' + re.escape(w) + r'\\b', c_lower) for w in academic_indicators):\n",
      "            category = \"ACADEMIC\"\n",
      "        elif any(re.search(r'\\b' + re.escape(w) + r'\\b', c_lower) for w in gov_indicators):\n",
      "            category = \"GOVERNMENT\"\n",
      "        elif any(re.search(r'\\b' + re.escape(w) + r'\\b', c_lower) for w in foundation_nonprofit):\n",
      "            category = \"FOUNDATION/NON-PROFIT\"\n",
      "            \n",
      "    # Final check: if category is still OTHER, but name contains a known big pharma name, upgrade to INDUSTRY\n",
      "    # This catches cases missed by simple indicators (e.g., just \"Bayer\")\n",
      "    if category == \"OTHER\":\n",
      "         big_pharma_shortlist = [\"novartis\", \"bayer\", \"roche\", \"pfizer\", \"gsk\", \"sanofi\", \"astrazeneca\", \"merck\", \"lilly\", \"abbvie\", \"bristol myers\", \"janssen\", \"amgen\", \"gilead\", \"takeda\"]\n",
      "         c_lower = consolidated_name.lower()\n",
      "         if any(re.search(r'\\b' + bp + r'\\b', c_lower) for bp in big_pharma_shortlist):\n",
      "              category = \"INDUSTRY\"\n",
      "              # Optional: Consolidate name further if just the name was found?\n",
      "              # Example: if 'bayer' found, ensure consolidated_name becomes 'Bayer'\n",
      "              for bp in big_pharma_shortlist:\n",
      "                   if re.search(r'\\b' + bp + r'\\b', c_lower):\n",
      "                        consolidated_name = bp.capitalize() # Simple capitalization, may need adjustment\n",
      "                        if bp == \"bristol myers\": consolidated_name = \"Bristol Myers Squibb\"\n",
      "                        if bp == \"gsk\": consolidated_name = \"GSK\"\n",
      "                        # Add more specific capitalizations if needed\n",
      "                        break\n",
      "\n",
      "    return category, consolidated_name\n",
      "\n",
      "def extract_and_categorize_sponsors(protocol_section: Dict) -> List[Dict]:\n",
      "    \"\"\"\n",
      "    Extracts lead sponsor and collaborators from the protocol section,\n",
      "    categorizes each using categorize_and_consolidate_organization, and returns\n",
      "    a list of structured sponsor dictionaries.\n",
      "    \"\"\"\n",
      "    sponsors_structured = []\n",
      "    if not isinstance(protocol_section, dict):\n",
      "        return sponsors_structured\n",
      "    \n",
      "    sponsor_module = protocol_section.get(\"sponsorCollaboratorsModule\", {})\n",
      "    if not isinstance(sponsor_module, dict):\n",
      "        return sponsors_structured\n",
      "\n",
      "    # Process Lead Sponsor\n",
      "    lead = sponsor_module.get(\"leadSponsor\", {})\n",
      "    if isinstance(lead, dict):\n",
      "        lead_name = lead.get(\"name\", \"\")\n",
      "        if lead_name:\n",
      "            cat, cons = categorize_and_consolidate_organization(lead_name)\n",
      "            sponsors_structured.append({\n",
      "                \"name\": lead_name,\n",
      "                \"consolidated_name\": cons,\n",
      "                \"role\": \"LEAD\",\n",
      "                \"type\": cat\n",
      "            })\n",
      "\n",
      "    # Process Collaborators\n",
      "    collabs = sponsor_module.get(\"collaborators\", [])\n",
      "    if isinstance(collabs, list):\n",
      "        for c in collabs:\n",
      "            if isinstance(c, dict):\n",
      "                collab_name = c.get(\"name\", \"\")\n",
      "                if collab_name:\n",
      "                    cat, cons = categorize_and_consolidate_organization(collab_name)\n",
      "                    sponsors_structured.append({\n",
      "                        \"name\": collab_name,\n",
      "                        \"consolidated_name\": cons,\n",
      "                        \"role\": \"COLLABORATOR\",\n",
      "                        \"type\": cat\n",
      "                    })\n",
      "    return sponsors_structured"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.6 Trial Phase Mapping\n",
      "\n",
      "Converts the raw phase list from trial data (e.g., `[\"PHASE1\", \"PHASE2\"]`) into standardized buckets used for aggregation and visualization (e.g., `[\"phase 1\", \"phase 2\"]`). Maps Phase 4 and unknown phases to `\"clinical trials\"`."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def get_trial_phases(phases_raw: List[str]) -> List[str]:\n",
      "    \"\"\"\n",
      "    Convert raw study phases (like 'PHASE1', 'PHASE2') into friendly buckets:\n",
      "    'phase 1', 'phase 2', 'phase 3', 'clinical trials' (for PHASE4 or N/A/Other).\n",
      "    If a study lists multiple recognized phases, includes them all.\n",
      "    Returns a sorted list of unique phase buckets.\n",
      "    \"\"\"\n",
      "    if not phases_raw or not isinstance(phases_raw, list):\n",
      "        # If no phase listed, default to 'clinical trials'\n",
      "        return [\"clinical trials\"]\n",
      "\n",
      "    mapped_phases = set()\n",
      "    has_specific_phase = False\n",
      "    for ph in phases_raw:\n",
      "        if not isinstance(ph, str):\n",
      "             continue\n",
      "        up = ph.upper()\n",
      "        if up in [\"EARLY_PHASE1\", \"PHASE1\"]:\n",
      "            mapped_phases.add(\"phase 1\")\n",
      "            has_specific_phase = True\n",
      "        elif up == \"PHASE2\":\n",
      "            mapped_phases.add(\"phase 2\")\n",
      "            has_specific_phase = True\n",
      "        elif up == \"PHASE3\":\n",
      "            mapped_phases.add(\"phase 3\")\n",
      "            has_specific_phase = True\n",
      "        elif up == \"PHASE4\" or up == \"NOT_APPLICABLE\": # Treat P4 and N/A as general clinical trials for this bucketing\n",
      "            mapped_phases.add(\"clinical trials\")\n",
      "        # else: # Other values like 'UNKNOWN_STATUS' implicitly fall through\n",
      "        #    pass\n",
      "            \n",
      "    # If no specific phase (1, 2, 3) was found, but phases were listed (e.g., just P4 or N/A),\n",
      "    # ensure 'clinical trials' bucket is present.\n",
      "    # If the input list was empty or contained only unrecognized strings, also default to 'clinical trials'.\n",
      "    if not has_specific_phase:\n",
      "         mapped_phases.add(\"clinical trials\")\n",
      "         \n",
      "    # Return unique sorted list\n",
      "    # Define a sort order for phases\n",
      "    phase_order = {\"phase 1\": 1, \"phase 2\": 2, \"phase 3\": 3, \"clinical trials\": 4}\n",
      "    return sorted(list(mapped_phases), key=lambda p: phase_order.get(p, 99))"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 4.7 Correctness Check / Debugging Helper\n",
      "\n",
      "Prints key details for a small random sample of studies, useful for quick manual verification of the filtering and extraction steps."
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
      "def correctness_check(studies: List[Dict], n=5):\n",
      "    \"\"\"\n",
      "    Randomly sample 'n' studies from the list and print key details \n",
      "    (NCT ID, Isotopes, Targets, Sponsors, Phase, Type) for quick sanity checks.\n",
      "    \"\"\"\n",
      "    if not studies:\n",
      "        logger.warning(\"Correctness check: No studies provided to sample.\")\n",
      "        return\n",
      "    \n",
      "    sample_size = min(n, len(studies))\n",
      "    if sample_size == 0:\n",
      "         logger.warning(\"Correctness check: No studies available to sample.\")\n",
      "         return\n",
      "         \n",
      "    logger.info(f\"\\n=== Random Correctness Check ({sample_size} studies) ===\")\n",
      "    chosen_indices = random.sample(range(len(studies)), sample_size)\n",
      "    \n",
      "    for i, study_index in enumerate(chosen_indices, 1):\n",
      "        st = studies[study_index]\n",
      "        # Safely get nested data\n",
      "        raw = st.get(\"original_data\", {})\n",
      "        proto = raw.get(\"protocolSection\", {})\n",
      "        id_mod = proto.get(\"identificationModule\", {})\n",
      "        design = proto.get(\"designModule\", {})\n",
      "        \n",
      "        nct_id = id_mod.get(\"nctId\", \"N/A\")\n",
      "        brief_title = id_mod.get(\"briefTitle\", \"N/A\")\n",
      "        isotopes = st.get(\"all_radioisotopes\", [])\n",
      "        targets = st.get(\"targets\", []) # Get extracted targets\n",
      "        phases_raw = design.get(\"phases\", [])\n",
      "        study_type = design.get(\"studyType\", \"N/A\")\n",
      "        sponsors = st.get(\"sponsors_structured\", [])\n",
      "        \n",
      "        print(f\"\\n--- Study {i}/{sample_size} (Index: {study_index}) ---\")\n",
      "        print(f\"  NCT ID: {nct_id}\")\n",
      "        print(f\"  Title: {brief_title[:100]}...\") # Print first 100 chars\n",
      "        print(f\"  Extracted Isotopes (Interventions only): {isotopes}\")\n",
      "        print(f\"  Extracted Targets: {targets}\") # Print targets\n",
      "        print(f\"  StudyType: {study_type}, Raw Phases: {phases_raw}\")\n",
      "        print(f\"  Sponsors (Industry Only):\")\n",
      "        industry_sponsors_found = False\n",
      "        for sp in sponsors:\n",
      "            if sp.get(\"type\") == \"INDUSTRY\":\n",
      "                print(f\"    - {sp.get('consolidated_name', sp.get('name'))} ({sp.get('role')}) - Orig: {sp.get('name')[:60]}\")\n",
      "                industry_sponsors_found = True\n",
      "        if not industry_sponsors_found:\n",
      "             print(\"    (None found or categorized as Industry)\")\n",
      "        # Optionally print other sponsor types too\n",
      "        # print(f\"  Sponsors (Other):\")\n",
      "        # other_sponsors_found = False\n",
      "        # for sp in sponsors:\n",
      "        #     if sp.get(\"type\") != \"INDUSTRY\":\n",
      "        #         print(f\"    - {sp.get('consolidated_name', sp.get('name'))} ({sp.get('type')} / {sp.get('role')})\")\n",
      "        #         other_sponsors_found = True\n",
      "        # if not other_sponsors_found:\n",
      "        #      print(\"    (None)\")\n",
      "             \n",
      "    print(f\"\\n=== End Correctness Check ===\")"
    ]
  },
  [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clinical Trial Radiopharmaceutical Analysis (Part 3: Analysis, Visualization & Execution)\n",
        "\n",
        "This final section includes:\n",
        "* Functions to summarize the filtered data.\n",
        "* A function to compare the script's output against a small, manually defined dataset (for debugging/validation).\n",
        "* The core function to build the structured data for visualization.\n",
        "* The main execution logic to run the entire pipeline and save the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summarize Filtered Data\n",
        "\n",
        "Calculates and displays summary statistics (phase counts, isotope usage, sponsor counts) for the final set of filtered studies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize(studies: List[Dict]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculates and prints summary statistics for the final list of studies.\n",
        "    Includes counts for phases, isotopes, targets, and industry sponsors.\n",
        "    Returns a dictionary containing these aggregated statistics.\n",
        "    \"\"\"\n",
        "    if not studies:\n",
        "        logger.info(\"Summarize: No final studies provided.\")\n",
        "        return {}\n",
        "\n",
        "    logger.info(f\"\\n=== SUMMARY of {len(studies)} Filtered Studies ===\")\n",
        "\n",
        "    phase_counter = Counter()\n",
        "    iso_counter = Counter()\n",
        "    target_counter = Counter() # Added target counter\n",
        "    sponsor_counter = Counter()\n",
        "    sponsor_type_counter = Counter()\n",
        "\n",
        "    for st in studies:\n",
        "        # --- Phases ---\n",
        "        design = st.get(\"original_data\", {}).get(\"protocolSection\", {}).get(\"designModule\", {})\n",
        "        phases_raw = design.get(\"phases\", [])\n",
        "        # Use the mapping function to get standardized buckets\n",
        "        phase_buckets = get_trial_phases(phases_raw)\n",
        "        for ph_bucket in phase_buckets:\n",
        "            phase_counter[ph_bucket] += 1 # Count each bucket instance\n",
        "            \n",
        "        # --- Isotopes ---\n",
        "        for iso in st.get(\"all_radioisotopes\", []):\n",
        "            iso_counter[iso] += 1\n",
        "\n",
        "        # --- Targets ---\n",
        "        for tgt in st.get(\"targets\", []):\n",
        "            target_counter[tgt] += 1\n",
        "\n",
        "        # --- Sponsors ---\n",
        "        sstruct = st.get(\"sponsors_structured\", [])\n",
        "        industry_sponsors_in_study = set() # Count each sponsor only once per study\n",
        "        all_sponsor_types_in_study = set()\n",
        "        for s in sstruct:\n",
        "             sponsor_type = s.get(\"type\", \"UNKNOWN\")\n",
        "             all_sponsor_types_in_study.add(sponsor_type)\n",
        "             if sponsor_type == \"INDUSTRY\":\n",
        "                 cname = s.get(\"consolidated_name\", s.get(\"name\"))\n",
        "                 if cname not in industry_sponsors_in_study:\n",
        "                     sponsor_counter[cname] += 1\n",
        "                     industry_sponsors_in_study.add(cname)\n",
        "                     \n",
        "        # Count sponsor types (1 per study that has that type)\n",
        "        for sp_type in all_sponsor_types_in_study:\n",
        "             sponsor_type_counter[sp_type] += 1\n",
        "             \n",
        "    # --- Print Summaries ---\n",
        "    print(\"\\n-- Phase Distribution (Studies might appear in multiple buckets) --\")\n",
        "    # Sort phases for printing\n",
        "    phase_order = {\"phase 1\": 1, \"phase 2\": 2, \"phase 3\": 3, \"clinical trials\": 4}\n",
        "    table_ph = sorted(phase_counter.items(), key=lambda item: phase_order.get(item[0], 99))\n",
        "    print(tabulate(table_ph, headers=[\"Phase Bucket\", \"Count\"], tablefmt=\"github\"))\n",
        "\n",
        "    print(\"\\n-- Isotope Usage (Top 20) --\")\n",
        "    top_iso = iso_counter.most_common(20)\n",
        "    iso_table = []\n",
        "    for iso, cnt in top_iso:\n",
        "        c = RADIOISOTOPE_CLASSIFICATION.get(iso, {})\n",
        "        iso_table.append([iso, cnt, c.get(\"type\", \"N/A\"), c.get(\"application\", \"N/A\")])\n",
        "    print(tabulate(iso_table, headers=[\"Isotope\", \"Count\", \"Type\", \"Application\"], tablefmt=\"github\"))\n",
        "\n",
        "    print(\"\\n-- Target Usage (Top 20) --\") # Added Target Summary\n",
        "    top_tgt = target_counter.most_common(20)\n",
        "    tgt_table = [[tgt, cnt] for tgt, cnt in top_tgt]\n",
        "    print(tabulate(tgt_table, headers=[\"Target\", \"Count\"], tablefmt=\"github\"))\n",
        "\n",
        "    print(\"\\n-- Industry Sponsors (Top 20) --\")\n",
        "    top_sp = sponsor_counter.most_common(20)\n",
        "    sp_table = [[n, c] for n, c in top_sp]\n",
        "    print(tabulate(sp_table, headers=[\"Sponsor (Consolidated)\", \"Study Count\"], tablefmt=\"github\"))\n",
        "    \n",
        "    print(\"\\n-- Sponsor Type Distribution --\")\n",
        "    type_table = [[stype, cnt] for stype, cnt in sponsor_type_counter.items()]\n",
        "    print(tabulate(type_table, headers=[\"Sponsor Type\", \"Study Count\"], tablefmt=\"github\"))\n",
        "    print(\"=== END SUMMARY ===\")\n",
        "\n",
        "    # --- Return Aggregated Data ---\n",
        "    aggregated_stats = {\n",
        "        \"total_studies_analyzed\": len(studies),\n",
        "        \"phase_bucket_counts\": dict(phase_counter),\n",
        "        \"isotope_counts\": dict(iso_counter),\n",
        "        \"target_counts\": dict(target_counter), # Added targets\n",
        "        \"industry_sponsor_counts\": dict(sponsor_counter),\n",
        "        \"sponsor_type_counts\": dict(sponsor_type_counter)\n",
        "    }\n",
        "    return aggregated_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Manual Data Comparison (Debugging Aid)\n",
        "\n",
        "Provides a placeholder function `get_manual_pipeline_data` to define a small set of expected outcomes for specific companies/trials. The `compare_output_with_manual_v3` function then compares the script's aggregated results against this manual data, highlighting discrepancies. This is primarily for validation and debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_manual_pipeline_data() -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Dummy function providing a small, hardcoded manual dataset.\n",
        "    Expand this or load from an external file (e.g., CSV, JSON) for real use.\n",
        "    Structure expects keys like: company, company_norm, is_therapeutic, \n",
        "                              stage_norm (set), target_norm (str), isotope_norm (str)\n",
        "    \"\"\"\n",
        "    # Example structure - Replace with actual manual data if available\n",
        "    return [\n",
        "        {\n",
        "            \"company\": \"Novartis\",\n",
        "            \"company_norm\": \"novartis\",\n",
        "            \"is_therapeutic\": True,\n",
        "            \"stage_norm\": {\"phase 3\", \"phase 2\"}, # Example phases\n",
        "            \"target_norm\": \"psma\", # Example target\n",
        "            \"isotope_norm\": \"lutetium-177\" # Example isotope\n",
        "        },\n",
        "        {\n",
        "            \"company\": \"Bayer\",\n",
        "            \"company_norm\": \"bayer\",\n",
        "            \"is_therapeutic\": True,\n",
        "            \"stage_norm\": {\"phase 2\", \"phase 1\"},\n",
        "            \"target_norm\": \"psma\", # Can add more targets if needed\n",
        "            \"isotope_norm\": \"actinium-225\"\n",
        "        },\n",
        "         {\n",
        "            \"company\": \"Telix Pharmaceuticals\",\n",
        "            \"company_norm\": \"telix\", # Assuming consolidation maps it here\n",
        "            \"is_therapeutic\": True, \n",
        "            \"stage_norm\": {\"phase 3\"},\n",
        "            \"target_norm\": \"psma\",\n",
        "            \"isotope_norm\": \"zirconium-89\" # Example: Illucix is diagnostic, but check if they have therapeutic trials too\n",
        "            # Note: Manual data needs careful verification!\n",
        "        },\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_output_with_manual_v3(aggregated_stats: Dict[str, Any], final_studies: List[Dict]):\n",
        "    \"\"\"\n",
        "    Compares aggregated script output (sponsors, phases, isotopes, targets) \n",
        "    against the manual data loaded by get_manual_pipeline_data.\n",
        "    Focuses on checking if data points expected from the manual table are found \n",
        "    in the script's results for specific companies.\n",
        "    \"\"\"\n",
        "    logger.info(\"\\n--- COMPARISON WITH MANUAL TABLE (V3) ---\")\n",
        "\n",
        "    script_companies_stats = aggregated_stats.get(\"industry_sponsor_counts\", {})\n",
        "    manual_data = get_manual_pipeline_data()\n",
        "    if not manual_data:\n",
        "        logger.warning(\"No manual data loaded, skipping comparison.\")\n",
        "        print(\"--- END COMPARISON (V3) ---\")\n",
        "        return\n",
        "\n",
        "    # Aggregate manual data by normalized company name\n",
        "    manual_companies = defaultdict(lambda: {\n",
        "        \"stages\": set(), \n",
        "        \"targets\": set(), \n",
        "        \"isotopes\": set(),\n",
        "        \"original_names\": set(), \n",
        "        \"is_therapeutic_list\": []\n",
        "    })\n",
        "\n",
        "    for row in manual_data:\n",
        "        comp_norm = row.get(\"company_norm\", \"unknown\").lower()\n",
        "        if comp_norm == \"unknown\": continue\n",
        "        \n",
        "        manual_companies[comp_norm][\"original_names\"].add(row.get(\"company\", \"N/A\"))\n",
        "        manual_companies[comp_norm][\"is_therapeutic_list\"].append(row.get(\"is_therapeutic\"))\n",
        "        # Only aggregate stages/targets/isotopes if manually marked as therapeutic (or adjust as needed)\n",
        "        if row.get(\"is_therapeutic\"):\n",
        "            if row.get(\"stage_norm\") and isinstance(row[\"stage_norm\"], set):\n",
        "                manual_companies[comp_norm][\"stages\"].update(row[\"stage_norm\"])\n",
        "            if row.get(\"target_norm\") and isinstance(row[\"target_norm\"], str):\n",
        "                 manual_companies[comp_norm][\"targets\"].add(row[\"target_norm\"].lower())\n",
        "            if row.get(\"isotope_norm\") and isinstance(row[\"isotope_norm\"], str):\n",
        "                manual_companies[comp_norm][\"isotopes\"].add(row[\"isotope_norm\"].lower())\n",
        "\n",
        "    # Compare each manual company entry against script results\n",
        "    script_company_names_lower = {name.lower(): name for name in script_companies_stats.keys()}\n",
        "    \n",
        "    for comp_norm, info in sorted(manual_companies.items()):\n",
        "        print(f\"\\n- Manual Company: '{'/'.join(info['original_names'])}' (Normalized: {comp_norm})\")\n",
        "        matched = False\n",
        "        \n",
        "        # Check if the normalized name exists in the script's consolidated sponsor list\n",
        "        if comp_norm in script_company_names_lower:\n",
        "            original_script_name = script_company_names_lower[comp_norm]\n",
        "            script_count = script_companies_stats[original_script_name]\n",
        "            print(f\"  - Found in script results as '{original_script_name}' with {script_count} studies.\")\n",
        "            matched = True\n",
        "\n",
        "            # Aggregate phases, isotopes, targets found by the script for this company\n",
        "            script_phases = set()\n",
        "            script_isotopes = set()\n",
        "            script_targets = set()\n",
        "\n",
        "            for st in final_studies:\n",
        "                sstruct = st.get(\"sponsors_structured\", [])\n",
        "                is_company_sponsor = any(\n",
        "                    s.get(\"consolidated_name\", \"\").lower() == comp_norm and s.get(\"type\") == \"INDUSTRY\"\n",
        "                    for s in sstruct\n",
        "                )\n",
        "                \n",
        "                if is_company_sponsor:\n",
        "                    # Phases\n",
        "                    ph_raw = st.get(\"original_data\", {}).get(\"protocolSection\", {}).get(\"designModule\", {}).get(\"phases\", [])\n",
        "                    mapped_phases = get_trial_phases(ph_raw) # Get standardized buckets\n",
        "                    script_phases.update(mapped_phases)\n",
        "                    \n",
        "                    # Isotopes\n",
        "                    script_isotopes.update(st.get(\"all_radioisotopes\", []))\n",
        "                    \n",
        "                    # Targets\n",
        "                    script_targets.update(st.get(\"targets\", []))\n",
        "\n",
        "            # Compare script findings vs manual expectations\n",
        "            # Note: Manual stages are already lowercase sets\n",
        "            missing_ph = info[\"stages\"] - script_phases\n",
        "            if info[\"stages\"] and missing_ph:\n",
        "                print(f\"    - Mismatch: Script phases ({script_phases}) MISSING expected manual stage(s): {missing_ph}\")\n",
        "            elif info[\"stages\"]:\n",
        "                 print(f\"    - Phases OK: Script ({script_phases}) covers Manual ({info['stages']})\")\n",
        "            else:\n",
        "                 print(f\"    - Phases: No therapeutic phases in manual data to compare.\")\n",
        "                 \n",
        "            # Note: Manual isotopes/targets are lowercase sets\n",
        "            script_isotopes_lower = {iso.lower() for iso in script_isotopes}\n",
        "            missing_iso = info[\"isotopes\"] - script_isotopes_lower\n",
        "            if info[\"isotopes\"] and missing_iso:\n",
        "                print(f\"    - Mismatch: Script isotopes ({script_isotopes_lower}) MISSING expected manual isotope(s): {missing_iso}\")\n",
        "            elif info[\"isotopes\"]:\n",
        "                 print(f\"    - Isotopes OK: Script ({script_isotopes_lower}) covers Manual ({info['isotopes']})\")\n",
        "            else:\n",
        "                 print(f\"    - Isotopes: No therapeutic isotopes in manual data to compare.\")\n",
        "                 \n",
        "            script_targets_lower = {tgt.lower() for tgt in script_targets}\n",
        "            missing_tgt = info[\"targets\"] - script_targets_lower\n",
        "            if info[\"targets\"] and missing_tgt:\n",
        "                print(f\"    - Mismatch: Script targets ({script_targets_lower}) MISSING expected manual target(s): {missing_tgt}\")\n",
        "            elif info[\"targets\"]:\n",
        "                 print(f\"    - Targets OK: Script ({script_targets_lower}) covers Manual ({info['targets']})\")\n",
        "            else:\n",
        "                 print(f\"    - Targets: No therapeutic targets in manual data to compare.\")\n",
        "                 \n",
        "        # If company from manual list (marked therapeutic) wasn't found in script output\n",
        "        if not matched and any(info[\"is_therapeutic_list\"]):\n",
        "            print(f\"  - WARNING: Not found in script's aggregated industry sponsor results (but manual data exists and marks as therapeutic).\")\n",
        "        elif not matched:\n",
        "            print(f\"  - INFO: Not found in script's aggregated industry sponsor results (and not marked therapeutic in manual data).\")\n",
        "\n",
        "    print(\"\\n--- END COMPARISON (V3) ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Build Data for Visualization\n",
        "\n",
        "This is the core function to transform the filtered list of studies into a structured JSON format suitable for driving interactive visualizations. It aggregates data by isotope, target, and company, broken down by clinical trial phase buckets. \n",
        "\n",
        "**Key Logic:**\n",
        "* Iterates through each filtered study.\n",
        "* Determines the study's phase buckets (e.g., \"phase 1\", \"phase 2\").\n",
        "* Identifies associated isotopes, targets, sponsors, and diseases.\n",
        "* Determines if the study uses diagnostic or therapeutic isotopes.\n",
        "* For **each phase bucket** the study belongs to, it updates the statistics for every associated isotope, target, and company within that specific phase bucket.\n",
        "* **Important:** A single study listed as Phase 1/Phase 2 will contribute to the counts and lists in *both* the \"phase 1\" and \"phase 2\" buckets for its associated entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_visualization_data(studies: List[Dict]) -> Dict:\n",
        "    \"\"\"\n",
        "    Builds a nested dictionary structure for visualization.\n",
        "    Aggregates data by isotope, target, and company, further broken down by phase bucket.\n",
        "    For each entity (e.g., 'lutetium-177') and phase (e.g., 'phase 3'), it collects:\n",
        "      - study_counts: {all, diagnostic, therapy}\n",
        "      - diseases: {count, list}\n",
        "      - companies: {count, list} (for isotopes/targets only)\n",
        "    Handles studies potentially belonging to multiple phase buckets.\n",
        "    \"\"\"\n",
        "    logger.info(f\"Building visualization data for {len(studies)} studies...\")\n",
        "    \n",
        "    # Define the standard phase buckets we aggregate into\n",
        "    PHASE_BUCKETS = [\"phase 1\", \"phase 2\", \"phase 3\", \"clinical trials\"]\n",
        "\n",
        "    def empty_phase_record(with_companies: bool = True):\n",
        "        \"\"\"Helper to create the standard record structure for an entity within a phase.\"\"\"\n",
        "        record = {\n",
        "            \"study_counts\": {\"all\": 0, \"diagnostic\": 0, \"therapy\": 0},\n",
        "            \"diseases\": set(),\n",
        "            # Store associated NCT IDs for potential drill-down\n",
        "            \"nct_ids\": set() \n",
        "        }\n",
        "        if with_companies:\n",
        "            record[\"companies\"] = set()\n",
        "        return record\n",
        "\n",
        "    # Initialize the main data structure using defaultdict for easier nesting\n",
        "    visualization_data = {\n",
        "        \"isotope\": defaultdict(lambda: {ph: empty_phase_record(with_companies=True) for ph in PHASE_BUCKETS}),\n",
        "        \"target\": defaultdict(lambda: {ph: empty_phase_record(with_companies=True) for ph in PHASE_BUCKETS}),\n",
        "        \"company\": defaultdict(lambda: {ph: empty_phase_record(with_companies=False) for ph in PHASE_BUCKETS}) # Changed key to 'company'\n",
        "    }\n",
        "\n",
        "    processed_count = 0\n",
        "    for st in studies:\n",
        "        processed_count += 1\n",
        "        if processed_count % 1000 == 0:\n",
        "             logger.info(f\"  ...processing study {processed_count}/{len(studies)} for visualization\")\n",
        "             \n",
        "        # --- Extract key info for this study ---\n",
        "        nct_id = st.get(\"original_data\", {}).get(\"protocolSection\", {}).get(\"identificationModule\", {}).get(\"nctId\", None)\n",
        "        if not nct_id:\n",
        "             continue # Should ideally have an NCT ID\n",
        "             \n",
        "        isotopes = st.get(\"all_radioisotopes\", [])\n",
        "        targets = st.get(\"targets\", [])\n",
        "        sponsors_structured = st.get(\"sponsors_structured\", [])\n",
        "        \n",
        "        # Get industry sponsors (consolidated names)\n",
        "        industry_sponsors = sorted(list(set(\n",
        "            s.get(\"consolidated_name\", s.get(\"name\"))\n",
        "            for s in sponsors_structured if s.get(\"type\") == \"INDUSTRY\"\n",
        "        )))\n",
        "\n",
        "        # Get disease conditions\n",
        "        conditions_list = st.get(\"original_data\", {}).get(\"protocolSection\", {}).get(\"conditionsModule\", {}).get(\"conditions\", [])\n",
        "        study_diseases = set()\n",
        "        for c in conditions_list:\n",
        "            # Extract condition name robustly (handle strings or dicts)\n",
        "            condition_name = None\n",
        "            if isinstance(c, str):\n",
        "                condition_name = c.strip()\n",
        "            elif isinstance(c, dict):\n",
        "                # Try common keys for condition name within the dict\n",
        "                for key in [\"name\", \"conditionName\", \"condition\", \"disease\"]:\n",
        "                    if key in c and isinstance(c[key], str) and c[key].strip():\n",
        "                        condition_name = c[key].strip()\n",
        "                        break\n",
        "            if condition_name:\n",
        "                study_diseases.add(condition_name)\n",
        "        study_diseases_list = sorted(list(study_diseases)) # Keep as sorted list\n",
        "\n",
        "        # Determine diagnostic/therapeutic nature based on isotope application\n",
        "        is_diagnostic = any(\n",
        "             RADIOISOTOPE_CLASSIFICATION.get(iso, {}).get(\"application\") in [\"diagnostic\", \"both\"] \n",
        "             for iso in isotopes\n",
        "        )\n",
        "        is_therapy = any(\n",
        "             RADIOISOTOPE_CLASSIFICATION.get(iso, {}).get(\"application\") in [\"therapeutic\", \"both\"] \n",
        "             for iso in isotopes\n",
        "        )\n",
        "\n",
        "        # Get the phase buckets this study belongs to\n",
        "        design = st.get(\"original_data\", {}).get(\"protocolSection\", {}).get(\"designModule\", {})\n",
        "        raw_phases = design.get(\"phases\", [])\n",
        "        phase_buckets = get_trial_phases(raw_phases)\n",
        "\n",
        "        # --- Update aggregates for EACH phase bucket the study falls into ---\n",
        "        for phase_bucket in phase_buckets:\n",
        "            if phase_bucket not in PHASE_BUCKETS:\n",
        "                 continue # Should not happen with get_trial_phases logic, but safeguard\n",
        "                 \n",
        "            # (1) Update Isotopes\n",
        "            for iso in isotopes:\n",
        "                slot = visualization_data[\"isotope\"][iso][phase_bucket]\n",
        "                slot[\"study_counts\"][\"all\"] += 1\n",
        "                if is_diagnostic: slot[\"study_counts\"][\"diagnostic\"] += 1\n",
        "                if is_therapy: slot[\"study_counts\"][\"therapy\"] += 1\n",
        "                slot[\"diseases\"].update(study_diseases_list)\n",
        "                slot[\"companies\"].update(industry_sponsors)\n",
        "                slot[\"nct_ids\"].add(nct_id)\n",
        "\n",
        "            # (2) Update Targets\n",
        "            for tgt in targets:\n",
        "                slot = visualization_data[\"target\"][tgt][phase_bucket]\n",
        "                slot[\"study_counts\"][\"all\"] += 1\n",
        "                if is_diagnostic: slot[\"study_counts\"][\"diagnostic\"] += 1\n",
        "                if is_therapy: slot[\"study_counts\"][\"therapy\"] += 1\n",
        "                slot[\"diseases\"].update(study_diseases_list)\n",
        "                slot[\"companies\"].update(industry_sponsors)\n",
        "                slot[\"nct_ids\"].add(nct_id)\n",
        "\n",
        "            # (3) Update Companies\n",
        "            for comp in industry_sponsors:\n",
        "                slot = visualization_data[\"company\"][comp][phase_bucket]\n",
        "                slot[\"study_counts\"][\"all\"] += 1\n",
        "                if is_diagnostic: slot[\"study_counts\"][\"diagnostic\"] += 1\n",
        "                if is_therapy: slot[\"study_counts\"][\"therapy\"] += 1\n",
        "                slot[\"diseases\"].update(study_diseases_list)\n",
        "                slot[\"nct_ids\"].add(nct_id)\n",
        "                \n",
        "    logger.info(\"Finalizing visualization data structure...\")\n",
        "\n",
        "    # --- Finalize: Convert sets to sorted lists and add counts ---\n",
        "    def finalize_record(record: dict, with_companies: bool):\n",
        "        # Finalize diseases\n",
        "        disease_list = sorted(list(record[\"diseases\"]))\n",
        "        record[\"diseases\"] = {\n",
        "            \"count\": len(disease_list),\n",
        "            \"list\": disease_list\n",
        "        }\n",
        "        # Finalize companies if present\n",
        "        if with_companies:\n",
        "            company_list = sorted(list(record[\"companies\"]))\n",
        "            record[\"companies\"] = {\n",
        "                \"count\": len(company_list),\n",
        "                \"list\": company_list\n",
        "            }\n",
        "        # Finalize NCT IDs\n",
        "        nct_list = sorted(list(record[\"nct_ids\"]))\n",
        "        record[\"nct_ids\"] = {\n",
        "            \"count\": len(nct_list),\n",
        "            \"list\": nct_list\n",
        "        }\n",
        "        \n",
        "\n",
        "    for entity_type, entities in visualization_data.items():\n",
        "        is_company_entity = (entity_type == \"company\")\n",
        "        for entity_name, phase_map in entities.items():\n",
        "            for phase_bucket, record in phase_map.items():\n",
        "                 # Only finalize if the record was actually populated (count > 0)\n",
        "                 if record[\"study_counts\"][\"all\"] > 0:\n",
        "                      finalize_record(record, with_companies=not is_company_entity)\n",
        "                 else:\n",
        "                      # Optional: Clean up empty phase records? Or keep them structure?\n",
        "                      # Keeping them might be simpler for consistent frontend access.\n",
        "                      # Finalize empty sets to empty lists for consistency\n",
        "                      finalize_record(record, with_companies=not is_company_entity)\n",
        "                      \n",
        "\n",
        "    # Convert defaultdicts to regular dicts for clean JSON output\n",
        "    def deep_dict(d):\n",
        "        if isinstance(d, defaultdict):\n",
        "            d = {k: deep_dict(v) for k, v in d.items()}\n",
        "        elif isinstance(d, dict):\n",
        "             d = {k: deep_dict(v) for k, v in d.items()}\n",
        "        # elif isinstance(d, set): # Sets should be converted by finalize_record\n",
        "        #     return sorted(list(d)) \n",
        "        return d\n",
        "        \n",
        "    final_visualization_data = deep_dict(visualization_data)\n",
        "    logger.info(\"Visualization data build complete.\")\n",
        "    return final_visualization_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Main Execution\n",
        "\n",
        "This function orchestrates the entire process:\n",
        "1.  Loads the input data (`consolidated_studies.json`).\n",
        "2.  Iterates through studies, applying filters:\n",
        "    * Must be 'INTERVENTIONAL'.\n",
        "    * Must have at least one 'INDUSTRY' sponsor.\n",
        "    * Must have at least one recognized radioisotope identified *within the intervention names*.\n",
        "3.  Extracts isotopes, targets, and structured sponsor info for filtered studies.\n",
        "4.  Calls the `summarize` function.\n",
        "5.  Runs optional verification checks (`correctness_check`, `compare_output_with_manual_v3`).\n",
        "6.  Calls `build_visualization_data`.\n",
        "7.  Saves the filtered studies list, aggregated stats, and visualization data to separate JSON files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the full analysis pipeline.\"\"\"\n",
        "    logger.info(f\"Starting analysis. Input file: {INPUT_FILE}\")\n",
        "    \n",
        "    # --- Load Input Data ---\n",
        "    if not os.path.exists(INPUT_FILE):\n",
        "        logger.error(f\"Input file not found: {INPUT_FILE}\")\n",
        "        return\n",
        "\n",
        "    all_studies = []\n",
        "    try:\n",
        "        with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            all_studies = json.load(f)\n",
        "        if not isinstance(all_studies, list):\n",
        "            logger.error(f\"Input JSON file {INPUT_FILE} must contain a list of studies.\")\n",
        "            return\n",
        "        logger.info(f\"Loaded {len(all_studies)} raw studies from {INPUT_FILE}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to read or parse JSON from {INPUT_FILE}: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- Filter Studies and Extract Information ---\n",
        "    logger.info(\"Filtering studies and extracting information...\")\n",
        "    final_studies = []\n",
        "    processed_count = 0\n",
        "    skipped_non_dict = 0\n",
        "    skipped_no_proto = 0\n",
        "    skipped_non_interventional = 0\n",
        "    skipped_no_industry = 0\n",
        "    skipped_no_isotope = 0\n",
        "\n",
        "    for idx, study in enumerate(all_studies, start=1):\n",
        "        processed_count += 1\n",
        "        if not isinstance(study, dict):\n",
        "            skipped_non_dict += 1\n",
        "            continue\n",
        "\n",
        "        raw = study.get(\"original_data\", {})\n",
        "        proto = raw.get(\"protocolSection\", {})\n",
        "        if not proto: \n",
        "            skipped_no_proto +=1\n",
        "            continue\n",
        "\n",
        "        design = proto.get(\"designModule\", {})\n",
        "\n",
        "        # Filter 1: Must be interventional\n",
        "        st_type = design.get(\"studyType\", \"\").upper()\n",
        "        if st_type != \"INTERVENTIONAL\":\n",
        "            skipped_non_interventional += 1\n",
        "            continue\n",
        "\n",
        "        # Filter 2: Must have at least one industry sponsor\n",
        "        sponsors = extract_and_categorize_sponsors(proto)\n",
        "        has_industry_sponsor = any(s.get(\"type\") == \"INDUSTRY\" for s in sponsors)\n",
        "        if not has_industry_sponsor:\n",
        "            skipped_no_industry += 1\n",
        "            continue\n",
        "\n",
        "        # Filter 3: Must have at least one recognized isotope IN INTERVENTIONS\n",
        "        arms_block = proto.get(\"armsInterventionsModule\", {})\n",
        "        iso_in_intervention = extract_isotopes_from_interventions_only(arms_block)\n",
        "        if not iso_in_intervention:\n",
        "            skipped_no_isotope += 1\n",
        "            continue\n",
        "\n",
        "        # If passes filters, extract targets and add info to study dict\n",
        "        extracted_targets = extract_targets(proto)\n",
        "        \n",
        "        study[\"all_radioisotopes\"] = iso_in_intervention\n",
        "        study[\"sponsors_structured\"] = sponsors\n",
        "        study[\"targets\"] = extracted_targets \n",
        "        final_studies.append(study)\n",
        "\n",
        "        if processed_count % 2000 == 0: # Log progress periodically\n",
        "             logger.info(f\"  ...processed {processed_count}/{len(all_studies)} studies...\")\n",
        "\n",
        "    # --- Log Filtering Summary ---\n",
        "    logger.info(f\"--- Filtering Summary ---\")\n",
        "    logger.info(f\"Total studies processed: {processed_count}\")\n",
        "    logger.info(f\"Skipped (not dict): {skipped_non_dict}\")\n",
        "    logger.info(f\"Skipped (no protocolSection): {skipped_no_proto}\")\n",
        "    logger.info(f\"Skipped (not INTERVENTIONAL): {skipped_non_interventional}\")\n",
        "    logger.info(f\"Skipped (no INDUSTRY sponsor): {skipped_no_industry}\")\n",
        "    logger.info(f\"Skipped (no recognized ISOTOPE in intervention): {skipped_no_isotope}\")\n",
        "    logger.info(f\"Total final studies included: {len(final_studies)}\")\n",
        "    \n",
        "    if not final_studies:\n",
        "         logger.warning(\"No studies remained after filtering. Exiting.\")\n",
        "         return\n",
        "\n",
        "    # --- Analysis and Output Generation ---\n",
        "    # Summaries\n",
        "    aggregated_stats = summarize(final_studies)\n",
        "\n",
        "    # Therapeutic Intent Verification (Informational)\n",
        "    truly_therapeutic_count = sum(\n",
        "        1 for st in final_studies\n",
        "        # Check both intent flags for this count\n",
        "        if has_any_therapeutic_isotope(st[\"all_radioisotopes\"]) and check_therapeutic_intent(st) \n",
        "    )\n",
        "    logger.info(f\"\\n[Verification] Among {len(final_studies)} included studies, \"\n",
        "                f\"{truly_therapeutic_count} appear 'therapeutic' based on isotope & intent checks.\")\n",
        "\n",
        "    # Correctness check (random sample)\n",
        "    correctness_check(final_studies, n=5)\n",
        "\n",
        "    # Compare with manual data\n",
        "    compare_output_with_manual_v3(aggregated_stats, final_studies)\n",
        "\n",
        "    # Build data visualization structure\n",
        "    visualization_data = build_visualization_data(final_studies)\n",
        "\n",
        "    # --- Write Output Files ---\n",
        "    # 1. Filtered Studies List\n",
        "    try:\n",
        "        with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as out:\n",
        "            json.dump(final_studies, out, indent=2, ensure_ascii=False)\n",
        "        logger.info(f\"Wrote {len(final_studies)} filtered studies to {OUTPUT_FILE}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed saving filtered studies to {OUTPUT_FILE}: {e}\")\n",
        "\n",
        "    # 2. Aggregated Statistics\n",
        "    try:\n",
        "        with open(OUTPUT_STATS_FILE, \"w\", encoding=\"utf-8\") as st_out:\n",
        "            json.dump(aggregated_stats, st_out, indent=2, ensure_ascii=False)\n",
        "        logger.info(f\"Saved aggregated stats to {OUTPUT_STATS_FILE}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed saving aggregated stats to {OUTPUT_STATS_FILE}: {e}\")\n",
        "\n",
        "    # 3. Visualization Data\n",
        "    try:\n",
        "        with open(OUTPUT_VISUALIZATION_FILE, \"w\", encoding=\"utf-8\") as vis_out:\n",
        "            json.dump(visualization_data, vis_out, indent=2, ensure_ascii=False)\n",
        "        logger.info(f\"Saved data visualization structure to {OUTPUT_VISUALIZATION_FILE}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving data visualization JSON to {OUTPUT_VISUALIZATION_FILE}: {e}\")\n",
        "\n",
        "    logger.info(\"Script execution completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Run Pipeline\n",
        "\n",
        "Execute the main function to run the entire analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if input file exists before running\n",
        "if os.path.exists(INPUT_FILE):\n",
        "    main()\n",
        "else:\n",
        "    logger.error(f\"Cannot run main function: Input file '{INPUT_FILE}' not found in the current directory.\")"
      ]
    }
  